#!/usr/bin/env python3
"""
Olympic CamGuard - å¢å¼· AI æ¸¬è©¦è…³æœ¬
å±•ç¤ºæœ€æ–°çš„åœ–åƒåˆ†æèƒ½åŠ›
"""

import asyncio
import time
import cv2
import numpy as np
from pathlib import Path
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_test_images():
    """å‰µå»ºæ¸¬è©¦åœ–åƒ"""
    test_images = {}

    # 1. å¥§é‹äº”ç’°æ¸¬è©¦åœ–åƒ
    olympic_rings_img = np.zeros((400, 600, 3), dtype=np.uint8)
    colors = [(255, 0, 0), (255, 255, 0), (0, 0, 0),
              (0, 255, 0), (0, 0, 255)]  # BGR format
    centers = [(120, 150), (200, 150), (280, 150), (160, 220), (240, 220)]

    for i, (center, color) in enumerate(zip(centers, colors)):
        cv2.circle(olympic_rings_img, center, 50, color, 8)

    _, encoded_rings = cv2.imencode('.jpg', olympic_rings_img)
    test_images['olympic_rings'] = encoded_rings.tobytes()

    # 2. é«”è‚²å ´å»ºç¯‰æ¸¬è©¦åœ–åƒ
    stadium_img = np.zeros((400, 600, 3), dtype=np.uint8)
    # ç¹ªè£½æ©¢åœ“é«”è‚²å ´
    cv2.ellipse(stadium_img, (300, 200), (250, 150),
                0, 0, 360, (128, 128, 128), 5)
    # ç¹ªè£½çœ‹å°éšæ¢¯
    for i in range(10):
        y = 100 + i * 15
        cv2.line(stadium_img, (50, y), (550, y), (200, 200, 200), 2)

    _, encoded_stadium = cv2.imencode('.jpg', stadium_img)
    test_images['stadium'] = encoded_stadium.tobytes()

    # 3. é‹å‹•å ´æ¨™è¨˜æ¸¬è©¦åœ–åƒ
    field_img = np.zeros((400, 600, 3), dtype=np.uint8)
    # ç¶ è‰²èƒŒæ™¯
    field_img[:] = (0, 128, 0)
    # ç™½è‰²æ¨™ç·š
    cv2.rectangle(field_img, (50, 50), (550, 350), (255, 255, 255), 3)
    cv2.circle(field_img, (300, 200), 80, (255, 255, 255), 3)
    cv2.line(field_img, (300, 50), (300, 350), (255, 255, 255), 3)

    _, encoded_field = cv2.imencode('.jpg', field_img)
    test_images['sports_field'] = encoded_field.tobytes()

    # 4. æ··åˆå ´æ™¯æ¸¬è©¦åœ–åƒ
    mixed_img = np.zeros((400, 600, 3), dtype=np.uint8)
    # é«”è‚²å ´çµæ§‹
    cv2.ellipse(mixed_img, (300, 200), (280, 180),
                0, 0, 360, (100, 100, 100), 3)
    # ä¸€äº›åœ“å½¢
    for i in range(3):
        cv2.circle(mixed_img, (150 + i*100, 100), 30, (0, 255, 255), 5)
    # ä¸€äº›çŸ©å½¢çµæ§‹
    cv2.rectangle(mixed_img, (100, 300), (500, 380), (255, 255, 255), 2)

    _, encoded_mixed = cv2.imencode('.jpg', mixed_img)
    test_images['mixed_scene'] = encoded_mixed.tobytes()

    return test_images


async def test_enhanced_ai_system():
    """æ¸¬è©¦å¢å¼·AIç³»çµ±"""
    try:
        # å°å…¥å¢å¼·AIæ¨¡çµ„
        from enhanced_ai_system import analyze_with_ultra_ai

        print("ğŸš€ é–‹å§‹æ¸¬è©¦è¶…å…ˆé€² AI æª¢æ¸¬ç³»çµ±...")
        print("=" * 60)

        # å‰µå»ºæ¸¬è©¦åœ–åƒ
        test_images = create_test_images()

        # æ¸¬è©¦æ¯å€‹åœ–åƒ
        for image_name, image_data in test_images.items():
            print(f"\nğŸ“¸ æ¸¬è©¦åœ–åƒ: {image_name}")
            print("-" * 40)

            start_time = time.time()

            # ä½¿ç”¨è¶…å…ˆé€²AIåˆ†æ
            result = await analyze_with_ultra_ai(image_data)

            analysis_time = time.time() - start_time

            # é¡¯ç¤ºçµæœ
            print(f"âœ… å ´é¤¨æª¢æ¸¬: {'æ˜¯' if result['is_venue_detected'] else 'å¦'}")
            print(f"ğŸ¯ ä¿¡å¿ƒåº¦: {result['confidence']:.3f}")
            print(f"âš ï¸  é¢¨éšªç­‰ç´š: {result['risk_level']}")
            print(f"ğŸ” æª¢æ¸¬å°è±¡: {', '.join(result['detected_objects'])}")
            print(f"â±ï¸  è™•ç†æ™‚é–“: {analysis_time:.3f}ç§’")

            if 'detailed_analysis' in result:
                detailed = result['detailed_analysis']
                print(f"ğŸ“Š è©³ç´°åˆ†æ:")

                if 'feature_scores' in detailed:
                    print("   ç‰¹å¾µåˆ†æ•¸:")
                    for feature, score in detailed['feature_scores'].items():
                        print(f"     â€¢ {feature}: {score:.3f}")

                if 'fusion_layers' in detailed:
                    fusion = detailed['fusion_layers']
                    print(f"   èåˆçµæœ: æœ€çµ‚={fusion.get('final', 0):.3f}, "
                          f"èª¿æ•´å¾Œ={fusion.get('adjusted', 0):.3f}")

                if 'image_quality_factor' in detailed:
                    print(f"   åœ–åƒå“è³ªå› å­: {detailed['image_quality_factor']:.3f}")

        print("\n" + "=" * 60)
        print("âœ… æ¸¬è©¦å®Œæˆï¼")

    except ImportError as e:
        print(f"âŒ ç„¡æ³•å°å…¥å¢å¼·AIæ¨¡çµ„: {e}")
        print("ğŸ’¡ ä½¿ç”¨åŸºç¤AIé€²è¡Œæ¸¬è©¦...")
        await test_basic_ai_system()
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")


async def test_basic_ai_system():
    """æ¸¬è©¦åŸºç¤AIç³»çµ±"""
    try:
        # å°å…¥ä¸»ç³»çµ±
        from main import analyze_image_for_venue, AIAnalysisResult

        print("ğŸ”§ ä½¿ç”¨åŸºç¤ AI æª¢æ¸¬ç³»çµ±...")

        # å‰µå»ºæ¸¬è©¦åœ–åƒ
        test_images = create_test_images()

        for image_name, image_data in test_images.items():
            print(f"\nğŸ“¸ æ¸¬è©¦åœ–åƒ: {image_name}")
            print("-" * 40)

            start_time = time.time()

            # ä½¿ç”¨åŸºç¤AIåˆ†æ
            result = analyze_image_for_venue(image_data)

            analysis_time = time.time() - start_time

            # é¡¯ç¤ºçµæœ
            print(f"âœ… å ´é¤¨æª¢æ¸¬: {'æ˜¯' if result.is_venue_detected else 'å¦'}")
            print(f"ğŸ¯ ä¿¡å¿ƒåº¦: {result.confidence:.3f}")
            print(f"âš ï¸  é¢¨éšªç­‰ç´š: {result.risk_level}")
            print(f"ğŸ” æª¢æ¸¬å°è±¡: {', '.join(result.detected_objects)}")
            print(f"â±ï¸  è™•ç†æ™‚é–“: {analysis_time:.3f}ç§’")

            if result.detailed_analysis:
                detailed = result.detailed_analysis
                print(f"ğŸ“Š è©³ç´°åˆ†æ:")

                if 'feature_scores' in detailed:
                    print("   ç‰¹å¾µåˆ†æ•¸:")
                    for feature, score in detailed['feature_scores'].items():
                        print(f"     â€¢ {feature}: {score:.3f}")

        print("\n" + "=" * 40)
        print("âœ… åŸºç¤æ¸¬è©¦å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ åŸºç¤æ¸¬è©¦å¤±æ•—: {e}")


def performance_comparison():
    """æ€§èƒ½æ¯”è¼ƒæ¸¬è©¦"""
    print("\nğŸ æ€§èƒ½æ¯”è¼ƒæ¸¬è©¦")
    print("=" * 50)

    test_images = create_test_images()
    sample_image = test_images['mixed_scene']

    # æ¸¬è©¦æ¬¡æ•¸
    test_rounds = 5

    try:
        # æ¸¬è©¦å¢å¼·AI
        print("ğŸš€ æ¸¬è©¦è¶…å…ˆé€²AI...")
        from enhanced_ai_system import analyze_with_ultra_ai_sync

        enhanced_times = []
        for i in range(test_rounds):
            start_time = time.time()
            result = analyze_with_ultra_ai_sync(sample_image)
            enhanced_times.append(time.time() - start_time)
            print(f"   ç¬¬{i+1}è¼ª: {enhanced_times[-1]:.3f}ç§’")

        avg_enhanced = sum(enhanced_times) / len(enhanced_times)
        print(f"ğŸ“Š è¶…å…ˆé€²AIå¹³å‡æ™‚é–“: {avg_enhanced:.3f}ç§’")

    except ImportError:
        print("âš ï¸  è¶…å…ˆé€²AIæ¨¡çµ„ä¸å¯ç”¨")
        avg_enhanced = 0

    try:
        # æ¸¬è©¦åŸºç¤AI
        print("\nğŸ”§ æ¸¬è©¦åŸºç¤AI...")
        from main import analyze_image_for_venue

        basic_times = []
        for i in range(test_rounds):
            start_time = time.time()
            result = analyze_image_for_venue(sample_image)
            basic_times.append(time.time() - start_time)
            print(f"   ç¬¬{i+1}è¼ª: {basic_times[-1]:.3f}ç§’")

        avg_basic = sum(basic_times) / len(basic_times)
        print(f"ğŸ“Š åŸºç¤AIå¹³å‡æ™‚é–“: {avg_basic:.3f}ç§’")

        if avg_enhanced > 0:
            speedup = avg_basic / avg_enhanced
            print(
                f"ğŸƒ æ€§èƒ½æ¯”è¼ƒ: è¶…å…ˆé€²AIç›¸å°æ–¼åŸºç¤AI {'å¿«' if speedup > 1 else 'æ…¢'} {abs(speedup-1)*100:.1f}%")

    except Exception as e:
        print(f"âŒ åŸºç¤AIæ¸¬è©¦å¤±æ•—: {e}")


def accuracy_test():
    """æº–ç¢ºåº¦æ¸¬è©¦"""
    print("\nğŸ¯ æº–ç¢ºåº¦æ¸¬è©¦")
    print("=" * 50)

    # é æœŸçµæœ
    expected_results = {
        'olympic_rings': {'venue_detected': True, 'min_confidence': 0.5},
        'stadium': {'venue_detected': True, 'min_confidence': 0.4},
        'sports_field': {'venue_detected': True, 'min_confidence': 0.4},
        'mixed_scene': {'venue_detected': True, 'min_confidence': 0.3}
    }

    test_images = create_test_images()

    try:
        from enhanced_ai_system import analyze_with_ultra_ai_sync

        print("ğŸ§ª æ¸¬è©¦è¶…å…ˆé€²AIæº–ç¢ºåº¦...")
        correct_predictions = 0
        total_tests = len(expected_results)

        for image_name, image_data in test_images.items():
            if image_name in expected_results:
                result = analyze_with_ultra_ai_sync(image_data)
                expected = expected_results[image_name]

                venue_correct = result['is_venue_detected'] == expected['venue_detected']
                confidence_ok = result['confidence'] >= expected['min_confidence']

                if venue_correct and confidence_ok:
                    correct_predictions += 1
                    status = "âœ…"
                else:
                    status = "âŒ"

                print(f"   {status} {image_name}: æª¢æ¸¬={result['is_venue_detected']}, "
                      f"ä¿¡å¿ƒåº¦={result['confidence']:.3f}")

        accuracy = correct_predictions / total_tests * 100
        print(
            f"ğŸ“Š è¶…å…ˆé€²AIæº–ç¢ºåº¦: {accuracy:.1f}% ({correct_predictions}/{total_tests})")

    except ImportError:
        print("âš ï¸  è¶…å…ˆé€²AIä¸å¯ç”¨ï¼Œè·³éæº–ç¢ºåº¦æ¸¬è©¦")


async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ… Olympic CamGuard - AI æª¢æ¸¬ç³»çµ±æ¸¬è©¦")
    print("=" * 60)

    # ä¸»è¦æ¸¬è©¦
    await test_enhanced_ai_system()

    # æ€§èƒ½æ¸¬è©¦
    performance_comparison()

    # æº–ç¢ºåº¦æ¸¬è©¦
    accuracy_test()

    print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼")

if __name__ == "__main__":
    # é‹è¡Œç•°æ­¥æ¸¬è©¦
    asyncio.run(main())
